{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCn0H/mcOycd94ME4BbXNQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatanadikatla/pytorch/blob/main/Week_9_Summative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1**\n",
        "\n",
        "Given an 5 Ã— 5 Ã— 2 input\n",
        "ğ¼\n",
        "I,calculate the result of the convolution with 3 Ã— 3 Ã— 2 filter\n",
        "ğ¾\n",
        "K and bias = 1, with stride = 2 and no padding."
      ],
      "metadata": {
        "id": "wLpXSnJ3zTiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer 1**\n",
        "**Showing my calculation process and result through manual for Question 1:**\n",
        "\n",
        "Given:\n",
        "\n",
        "\n",
        "*   Input I of size\n",
        "5\n",
        "Ã—\n",
        "5\n",
        "Ã—\n",
        "2\n",
        "*   Filter\n",
        "ğ¾\n",
        " of size\n",
        "3\n",
        "Ã—\n",
        "3\n",
        "Ã—\n",
        "2\n",
        "\n",
        "*   Bias = 1\n",
        "*   Stride (s) = 2\n",
        "\n",
        "\n",
        "*   No padding\n",
        "\n",
        "\n",
        "\n",
        "### Input Matrices:\n",
        "\n",
        "### Separating these two Input matrices into I1 and I2\n",
        "\n",
        "\n",
        "\\[I_1 =\n",
        "\\begin{bmatrix}\n",
        "2 & 2 & 0 & 1 & 1 \\\\\n",
        "2 & 1 & 0 & 1 & 0 \\\\\n",
        "1 & 2 & 0 & 2 & 1 \\\\\n",
        "2 & 0 & 1 & 0 & 0 \\\\\n",
        "1 & 0 & 0 & 1 & 0 \\\\\n",
        "\\end{bmatrix}\\]\n",
        "\n",
        "\n",
        "\n",
        "\\[I_2 = \\begin{bmatrix}\n",
        "1 & 1 & 0 & 2 & 2 \\\\\n",
        "1 & 0 & 2 & 1 & 0 \\\\\n",
        "1 & 2 & 2 & 1 & 2 \\\\\n",
        "0 & 1 & 1 & 0 & 1 \\\\\n",
        "0 & 0 & 1 & 2 & 2 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "### Filter Matrices:\n",
        "\n",
        "### Separating these two Filters into K1 and K2\n",
        "\n",
        "\\[K_1 = \\begin{bmatrix}\n",
        "-1 & -1 & 0 \\\\\n",
        "-1 & -1 & 1 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "\\[K_2 = \\begin{bmatrix}\n",
        "1 & 1 & 1 \\\\\n",
        "1 & 0 & -1 \\\\\n",
        "-1 & -1 & -1 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "\n",
        "## Steps for Convolution:\n",
        "### Determine the output dimensions:\n",
        "The formula for the output dimension with no padding and stride\n",
        "\n",
        "s is given by:\n",
        "\n",
        "Output Dimension\n",
        "= [(W-F)/s]+1\n",
        "\n",
        "where W is the input dimension and F is the filter dimension.\n",
        "\n",
        "For our case:\n",
        "\n",
        "Output Dimension\n",
        "=\n",
        "[(5 - 3) / 2]+1 = [2 / 2] + 1 = 2 (Output Height and Width)\n",
        "\n",
        "**So the output will be\n",
        "2 X 2 X 1**\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "### Steps for Convolution:\n",
        "\n",
        "#### Top-left corner(0,0):\n",
        "\n",
        "\\[ Region from I_1 =\n",
        "\\begin{bmatrix}\n",
        "2 & 2 & 0 \\\\\n",
        "2 & 1 & 0 \\\\\n",
        "1 & 2 & 0 \\\\\n",
        "\\end{bmatrix}\\]\n",
        "\n",
        "\n",
        "\n",
        "\\[I_2 = \\begin{bmatrix}\n",
        "1 & 1 & 0\\\\\n",
        "1 & 0 & 2\\\\\n",
        "1 & 2 & 2 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "Element-wise product sum:\n",
        "\n",
        "For I1 and K1:\n",
        "\n",
        "(2x-1)+(2x-1)+(0x0)+(2x-1)+(1x-1)+(0x1)+(1x0)+(2x1)+(0x1)\n",
        "=-2-2+0-2-1+0+0+2+0 = -5\n",
        "\n",
        "For I2 and K2:\n",
        "\n",
        "(1x1)+(1x1)+(0x1)+(1x1)+(0x0)+(2x-1)+(1x-1)+(2x-1)+(2x-1)\n",
        "=1+1+0+1+0-2-1-2-2 = -4\n",
        "\n",
        "**Sum and add bias: -5+(-4)+1 = -8**\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "#### Top-right corner(0,2):\n",
        "\n",
        "\\[ Region from I_1 =\n",
        "\\begin{bmatrix}\n",
        "0 & 1 & 1 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "0 & 2 & 1 \\\\\n",
        "\\end{bmatrix}\\]\n",
        "\n",
        "\n",
        "\\[ Region from I_2 = \\begin{bmatrix}\n",
        "0 & 2 & 2 \\\\\n",
        "2 & 1 & 0 \\\\\n",
        "2 & 1 & 2 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "Element-wise product sum:\n",
        "\n",
        "For I1 and K1:\n",
        "\n",
        "(0x-1)+(1x -1)+(1x0)+(0x-1)+(1x-1)+(0x1)+(0x0)+(2x1)+(1x1)\n",
        "\n",
        "= 0 - 1 + 0 - 0 - 1 + 0 + 0 + 2 + 1 = 1\n",
        "\n",
        "<br/>\n",
        "\n",
        "For I2 and K2:\n",
        "\n",
        "(0x1)+(2x1)+(2x1)+(2x1)+(1x0)+(0x-1)+(2x-1)+(1x-1)+(2x-1)\n",
        "\n",
        "= 0 + 2 + 2 + 2 + 0 + 0 - 2 - 1 - 2 = 1\n",
        "\n",
        "**Sum and add bias: 1+1+1 = 3**\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "#### Bottom-left corner(2,0):\n",
        "\n",
        "\n",
        "\\[Region from I_1 =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 0\\\\\n",
        "2 & 0 & 1\\\\\n",
        "1 & 0 & 0\\\\\n",
        "\\end{bmatrix}\\]\n",
        "\n",
        "\n",
        "\n",
        "\\[Region from I_2 = \\begin{bmatrix}\n",
        "1 & 2 & 2\\\\\n",
        "0 & 1 & 1\\\\\n",
        "0 & 0 & 1\\\\\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "Element-wise product sum:\n",
        "\n",
        "For I1 and K1:\n",
        "\n",
        "(1x-1)+(2x-1)+(0x0)+(2x-1)+(0x-1)+(1x1)+(1x0)+(0x1)+(0x1)\n",
        "\n",
        "= -1-2+0-2+0+1+0+0+0 = -4\n",
        "<br/>\n",
        "For I2 and K2:\n",
        "\n",
        "(1x1)+(2x1)+(2x1)+(0x1)+(1x0)+(1x-1)+(0x-1)+(0x-1)+(1x-1)\n",
        "\n",
        "= 1+2+2+0+0-1-0-0-1 = 3\n",
        "<br/>\n",
        "**Sum and add bias:-4+3+1 = 0**\n",
        "\n",
        "#### Bottom-right corner(2,2):\n",
        "\n",
        "\\[Region from I_1 =\n",
        "\\begin{bmatrix}\n",
        "0 & 2 & 1 \\\\\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "\\end{bmatrix}\\]\n",
        "\n",
        "\n",
        "\\[Region from I_2 = \\begin{bmatrix}\n",
        "2 & 1 & 2 \\\\\n",
        "1 & 0 & 1 \\\\\n",
        "1 & 2 & 2 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "\n",
        "Element-wise product sum:\n",
        "\n",
        "For I1 and K1:\n",
        "\n",
        "(0x-1)+(2x-1)+(1x0)+(1x-1)+(0x-1)+(0x1)+(0x0)+(1x1)+(0x1)\n",
        "\n",
        "= 0-2+0-1-0+0+0+1+0 = -2\n",
        "\n",
        "For I2 and K2:\n",
        "\n",
        "(2X1)+(1X1)+(2X1)+(1X1)+(0X0)+(1X-1)+(1X-1)+(2X-1)+(2X-1)\n",
        "\n",
        "= 2+1+2+1+0-1-1-2-2 = 0\n",
        "\n",
        "**Sum and add bias:-2+0+1 = -1**\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "The output feature map is:\n",
        "\\[\n",
        "\\begin{bmatrix}\n",
        "-8 & 3 \\\\\n",
        "0 & -1 \\\\\n",
        "\\end{bmatrix}\n",
        "\\]\n"
      ],
      "metadata": {
        "id": "nJQcr0aizTlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b/>\n",
        "<b/><b/>\n",
        "<b/><b/>\n",
        "<b/>\n",
        "<b/>\n",
        "<b/>\n",
        "<b/><b/>\n",
        "<b/><b/>\n",
        "<b/>\n",
        "<b/>\n",
        "<b/>\n",
        "<b/><b/>\n",
        "<b/><b/>\n",
        "<b/>\n",
        "<b/>"
      ],
      "metadata": {
        "id": "BJ3ZrhNrgxtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2**\n",
        "Calculate the result of applying ReLU to the answer of (a)."
      ],
      "metadata": {
        "id": "_o56eXxKgxzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the ReLU output through using the code.\n",
        "import torch\n",
        "conv_output = torch.tensor([[-8,3], [0, -1]])\n",
        "relu_output = torch.relu(conv_output)\n",
        "print(relu_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCcZfPIeHL6i",
        "outputId": "04730724-b1eb-4f1e-d69b-8bbb6462842d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 3],\n",
            "        [0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer 2**\n",
        "**Showing my calculation process and result through manual for Question 2:**\n",
        "\n",
        "To apply the ReLU activation function to the result of the convolution, we simply replace any negative values with 0 as it the ReLU function itself calls for ReLU(z) =  max(0,z).\n",
        "\n",
        "#### Given Convolution Ouput:\n",
        "\\[\n",
        "\\begin{bmatrix}\n",
        "-8 & 3 \\\\\n",
        "0 & -1 \\\\\n",
        "\\end{bmatrix}\n",
        "\\]\n",
        "\n",
        "Applying ReLU:\n",
        "\n",
        "\\[\n",
        "\\begin{bmatrix}\n",
        "ReLU(-8) & ReLU(3) \\\\\n",
        "ReLU(0) & ReLU(-1) \\\\\n",
        "\\end{bmatrix}\n",
        "\\]\n",
        "\n",
        "so, the result of applying ReLU to the conv ouput is:\n",
        "\\[\n",
        "\\begin{bmatrix}\n",
        "0 & 3 \\\\\n",
        "0 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "\\]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j9UO2pt_i5MG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "#**Question 3:**\n",
        "\n",
        "Given an input I, calculate the result of the max pooling with a 2 Ã— 2 filter, stride = 2.\n",
        "\n",
        "\\[\n",
        "I = \\begin{bmatrix}\n",
        "17 & 14 & 21 & 0 & 30 & 32 \\\\\n",
        "1 & 38 & 16 & 33 & 34 & 23 \\\\\n",
        "12 & 7 & 26 & 18 & 5 & 28 \\\\\n",
        "22 & 25 & 11 & 40 & 15 & 19 \\\\\n",
        "13 & 36 & 24 & 48 & 3 & 20 \\\\\n",
        "47 & 29 & 4 & 6 & 42 & 31 \\\\\n",
        "\\end{bmatrix}\n",
        "\\]"
      ],
      "metadata": {
        "id": "wyshg6Oht6Hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### **Answer 3**\n",
        "\n",
        "**Showing my calculation process and result through manual for Question 3 and below cell will display the answer in code:**\n",
        "\n",
        "#### In order to calculate the max pooling output, calculate the following output dimensions:\n",
        "\n",
        "\n",
        "*   Given filter size 2X2 (This indicates that we will look 2X2 regions of the input matrix (I) to perform the max pooling)\n",
        "*   Stride (s) = 2 (A stride of 2 means the filter moves 2 steps at a time)\n",
        "\n",
        "### Output Dimension\n",
        "= [(W-F)/s]+1\n",
        "\n",
        "where W is the input dimension and F is the filter dimension.\n",
        "\n",
        "For our case:\n",
        "\n",
        "Output Dimension\n",
        "=\n",
        "[(6 - 2) / 2]+1 = [4 / 2] + 1 = 3 (Output Height and Width)\n",
        "\n",
        "So the output will be\n",
        "3 X 3 X 1\n",
        "\n",
        "<br/>\n",
        "\n",
        "### Max Pooling Calculation:\n",
        "\n",
        "**Region (0,0) to (1,1)**\n",
        "This region includes the elements from the first and second rows and the first and second columns:\n",
        "\n",
        "\\[\\begin{bmatrix}\n",
        "17 & 14 \\\\\n",
        "1 & 38 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 38**\n",
        "<br/>\n",
        "<br/>\n",
        "**Region (0,2) to (1,3)**\n",
        "This region includes the elements from the first and second rows and the third and fourth columns:\n",
        "\\[\\begin{bmatrix}\n",
        "21 & 0 \\\\\n",
        "16 & 33 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 33**\n",
        "<br/>\n",
        "<br/>\n",
        "**Region (0,4) to (1,5)**\n",
        "This region includes the elements from the first and second rows and the fifth and sixth columns:\n",
        "\\[\\begin{bmatrix}\n",
        "30 & 32 \\\\\n",
        "34 & 23 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 34**\n",
        "<br/>\n",
        "<br/>\n",
        "**Region (2,0) to (3,1)**\n",
        "This region includes the elements from the third and fourth rows and the first and second columns:\n",
        "\\[\\begin{bmatrix}\n",
        "12 & 7 \\\\\n",
        "22 & 25 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 25**\n",
        "<br/>\n",
        "<br/>\n",
        "**Region (2,2) to (3,3)**\n",
        "This region includes the elements from the third and fourth rows and the third and fourth columns:\n",
        "\\[\\begin{bmatrix}\n",
        "26 & 18 \\\\\n",
        "11 & 40 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 40**\n",
        "<br/>\n",
        "<br/>\n",
        "**Region (2,4) to (3,5)**\n",
        "This region includes the elements from the third and fourth rows and the fifth and sixth columns:\n",
        "\\[\\begin{bmatrix}\n",
        "5 & 28 \\\\\n",
        "15 & 19 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 28**\n",
        "<br/>\n",
        "<br/>\n",
        "**Region (4,0) to (5,1)**\n",
        "This region includes the elements from the fifth and sixth rows and the first and second columns:\n",
        "\\[\\begin{bmatrix}\n",
        "13 & 36 \\\\\n",
        "47 & 29 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 47**\n",
        "<br/>\n",
        "<br/>\n",
        "**Region (4,2) to (5,3)**\n",
        "This region includes the elements from the fifth and sixth rows and the third and fourth columns:\n",
        "\\[\\begin{bmatrix}\n",
        "24 & 48 \\\\\n",
        "4 & 6 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 48**\n",
        "<br/>\n",
        "<br/>\n",
        "**Region (4,4) to (5,5)**\n",
        "This region includes the elements from the fifth and sixth rows and the fifth and sixth columns:\n",
        "\\[\\begin{bmatrix}\n",
        "3 & 20 \\\\\n",
        "42 & 31 \\\\\n",
        "\\end{bmatrix} \\]\n",
        "<br/>\n",
        "**Max Value: 42**\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### The final Max Pool output:\n",
        "\\\n",
        "\\begin{bmatrix}\n",
        "38 & 33 & 34 \\\\\n",
        "25 & 40 & 28 \\\\\n",
        "47 & 48 & 42 \\\\\n",
        "\\end{bmatrix}"
      ],
      "metadata": {
        "id": "GnrqyJNjuF7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer 3 through coding:\n",
        "import numpy as np\n",
        "\n",
        "# Given input matrix\n",
        "I = np.array([\n",
        "    [17, 14, 21, 0, 30, 32],\n",
        "    [1, 38, 16, 33, 34, 23],\n",
        "    [12, 7, 26, 18, 5, 28],\n",
        "    [22, 25, 11, 40, 15, 19],\n",
        "    [13, 36, 24, 48, 3, 20],\n",
        "    [47, 29, 4, 6, 42, 31]\n",
        "])\n",
        "\n",
        "# Max pooling with 2x2 filter and stride of 2\n",
        "pool_size = 2\n",
        "stride = 2\n",
        "\n",
        "output_dim = ((I.shape[0] - pool_size) // stride + 1, (I.shape[1] - pool_size) // stride + 1)\n",
        "pooled_output = np.zeros(output_dim)\n",
        "\n",
        "for i in range(0, I.shape[0], stride):\n",
        "    for j in range(0, I.shape[1], stride):\n",
        "        if i + pool_size <= I.shape[0] and j + pool_size <= I.shape[1]:\n",
        "            pooled_output[i//stride, j//stride] = np.max(I[i:i+pool_size, j:j+pool_size])\n",
        "\n",
        "print(\"Max Pooled Output:\")\n",
        "print(pooled_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtZ-oHLOisLq",
        "outputId": "5e8c2664-cc90-4db4-9460-9e145e2a5c26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Pooled Output:\n",
            "[[38. 33. 34.]\n",
            " [25. 40. 28.]\n",
            " [47. 48. 42.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>\n",
        "\n",
        "# Question 4:\n",
        "A CNN has the architecture given in the following table. For each layer, calculate the number of parameters and the size of corresponding feature maps. The notation follows the convention as below:\n",
        "\n",
        "CONV-K-N-L denotes a convolutional layer with N filters, each of the size KÃ—K, SAME1 padding and stride =L.\n",
        "\n",
        "POOL-K-L indicates a pooling layer with KÃ—K filter and stride = L.\n",
        "\n",
        "FC-N stands for a fully-connected layer with N neurons.\n",
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "gxjzyELXN9zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer 4**\n",
        "\n",
        "**Showing the calculation for Question 4 through manual calculations and below cell will display the answer in code:**\n",
        "\n",
        "**Input shape:32X32X3 and Parameters = 0**\n",
        "\n",
        "### **Conv 5-16-2:**\n",
        "\n",
        "\n",
        "*   Filter Size = 5 X 5\n",
        "*   Stride = 2\n",
        "*   Padding = same\n",
        "*   Number of Filters = 16\n",
        "\n",
        "<br/>\n",
        "\n",
        "**For same padding with stride 2, the output shape formula is:**\n",
        "\n",
        "\n",
        "*   Output size = [Input size/Stride]\n",
        "*   Output height and width: 32/2 = 16\n",
        "*   Output depth: 16\n",
        "\n",
        "**Conv 5-16-2 Feature map shape (1): 16X16X16 = 4096**\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Number of Parameters (2):**\n",
        "Parameters = (Filter Height X Filter Width X Input Depth + 1) X Number of Filters = (5 X 5 X 3 + 1) X 16 = **1216 Parameters**\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### **Pool 2-2 Layer:**\n",
        "*   Filter Size = 2 X 2\n",
        "*   Stride = 2\n",
        "\n",
        "\n",
        "*   Output size = [Input size/Stride]\n",
        "\n",
        "*   Output height and width: 16/2 = 8\n",
        "*   Output depth: 16 (No change in filters from Conv layer to Pool layer)\n",
        "\n",
        "\n",
        "**Pool 2-2 Feature map shape (3): 8X8X16 = 1024**\n",
        "<br/>\n",
        "\n",
        "**Number of Parameters (4):**\n",
        "Parameters = 0 (Pooling layer do not have parameters)\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### **Conv 3-32-1:**\n",
        "\n",
        "\n",
        "*   Filter Size = 3 X 3\n",
        "*   Stride = 1\n",
        "*   Padding = same\n",
        "*   Number of Filters = 32\n",
        "\n",
        "<br/>\n",
        "\n",
        "**For same padding with stride 1, the output shape formula is:**\n",
        "\n",
        "\n",
        "\n",
        "*   Output size = Input size\n",
        "\n",
        "*   Output height and width = 8\n",
        "*   Output depth: 32\n",
        "\n",
        "\n",
        "**Conv 3-32-1 Feature map shape (5) : 8X8X32 = 2048**\n",
        "<br/>\n",
        "\n",
        "**Number of Parameters (6) :**\n",
        "Parameters = (Filter Height X Filter Width X Input Depth + 1) X Number of Filters = (3 X 3 X 16 + 1) X 32 = **4640 Parameters**\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### **Pool 2-2 Layer:**\n",
        "\n",
        "\n",
        "*   Filter Size = 2 X 2\n",
        "*   Stride = 2\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "**For same padding with stride 2, the output shape formula is:**\n",
        "\n",
        "\n",
        "*   Output size = [Input size/Stride]\n",
        "\n",
        "*   Output height and width: 8/2 = 4\n",
        "*   Output depth: 32 (No change in filters from Conv layer to Pool layer)\n",
        "\n",
        "**Feature map shape(7): 4X4X32 = 512**\n",
        "<br/>\n",
        "\n",
        "**Number of Parameters (8):**\n",
        "Parameters = 0\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### **Flatten Layer:**\n",
        "\n",
        "Feature map shape: Flatten the feature map to 1D vector\n",
        "\n",
        "\n",
        "\n",
        "*   Output size  = 4X4X32 = 512\n",
        "*   Number of Parameters = 0\n",
        "\n",
        "### **FC-10:**\n",
        "\n",
        "*   Feature Map shape (9) = 10\n",
        "*   Parameters (10) = (Input size +1) X Number of Neurons = (512 + 1) X 10 = 5130\n",
        "\n",
        "\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "\n",
        "**Listed below number of parameters and corresponding Feature Maps:**\n",
        "\n",
        "*   1: Conv 5-16-2 Feature map shape: 16X16X16 = 4096\n",
        "\n",
        "*   2: Conv 5-16-2 Number of Parameters = 1216 Parameters\n",
        "\n",
        "*   3: Pool 2-2 Feature map shape: 8X8X16 = 1024\n",
        "\n",
        "*   4: Pool 2-2 Number of Parameters = 0\n",
        "*   5: Conv 3-32-1 Feature map shape: 8X8X32 = 2048\n",
        "\n",
        "*   6: Conv 3-32-1 Number of Parameters = 4640 Parameters\n",
        "\n",
        "\n",
        "*   7: Pool 2-2 Feature map shape: 4X4X32 = 512\n",
        "\n",
        "\n",
        "*   8: Pool 2-2 Number of Parameters = 0\n",
        "\n",
        "\n",
        "*   9: FC-10 Feature Map shape = 10\n",
        "*   10:FC-10 Number of Parameters = 5130 Parameters\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6f_m_VAMPCW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer 4 through Coding, used TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "#It seems to be showing an error saying \"tensorflow.keras\" could not be resolved (Tried many times doing pip install tensor flow but this is not resolved)\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(16, (5, 5), strides=2, padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
        "model.add(layers.Conv2D(32, (3, 3), strides=1, padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "# Compile the model\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "nu7fMMiL3JC6",
        "outputId": "ce693e51-5c8b-4fa6-bd3f-3ca58e3e6142"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)          â”‚           \u001b[38;5;34m1,216\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)            â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)            â”‚           \u001b[38;5;34m4,640\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)            â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  â”‚           \u001b[38;5;34m5,130\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,986\u001b[0m (42.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,986</span> (42.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,986\u001b[0m (42.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,986</span> (42.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "# Question 5:\n",
        "\n",
        "Consider a simple RNN with a linear activate function for one output defined by these equations, for\n",
        "\n",
        "\n",
        "\n",
        "st = c * (wx * xt + wrec * st-1)\n",
        "<br/>\n",
        "and\n",
        "y=c(wh * sT)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Assume\n",
        "\n",
        "wx = 4 , wrec = 2, wh = 3, s0 = 0, c = 2, T = 3, and x = (1, 2, 2)."
      ],
      "metadata": {
        "id": "cA5F45aYmgfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### **Answer 5:**\n",
        "\n",
        "**Showing the calculation for Question 5 through manual calculations and below cell will display the answer in code:**\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "Solving this problem to calculate st at each time step and then final state to compute the output y.\n",
        "\n",
        "**Based on the below equations:**\n",
        "\n",
        "st = c * (wx * xt + wrec * st-1)\n",
        "<br/>\n",
        "and\n",
        "y = c * (wh * sT)\n",
        "\n",
        "**With the assumption of the these values:**\n",
        "wx = 4 , wrec = 2, wh = 3, s0 = 0, c = 2, T = 3, and x = (1, 2, 2).\n",
        "\n",
        "**Lets Compute the state st at each time step:**\n",
        "<br/>\n",
        "\n",
        "**Time Step 1 (t=1):**\n",
        "\n",
        "*   s1 = c * (wx * x1 + wrec * s0) = 2 * (4 * 1 + 2 * 0) = 8\n",
        "<br/>\n",
        "\n",
        "**Time Step 2 (t=2):**\n",
        "\n",
        "\n",
        "*   s2 = c * (wx * x2 + wrec * s1) = 2 * (4 * 2 + 2 * 8) = 48\n",
        "<br/>\n",
        "\n",
        "**Time Step 3 (t=3):**\n",
        "\n",
        "\n",
        "*   s2 = c * (wx * x3 + wrec * s2) = 2 * (4 * 2 + 2 * 48) = 208\n",
        "<br/>\n",
        "\n",
        "**Now Lets calculate the output y:**\n",
        "\n",
        "y = c * (wh * sT)\n",
        "\n",
        "y = 2 * (3 * 208) = 1248\n",
        "\n",
        "**The Final output y is \"1248\"**\n",
        "\n"
      ],
      "metadata": {
        "id": "RGIQh_e-u8pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answering Question 5 through Python Code\n",
        "def rnn_output(x, wx, wrec, wh, s0, c):\n",
        "  st = s0\n",
        "  for xt in x:\n",
        "    st = c* (wx*xt + wrec*st)\n",
        "  y = c* (wh*st) # This shouldn't be in the for loop as it is not looping with xt\n",
        "  return y\n",
        "\n",
        "# Providing values as mentioned in Question 5 to this function\n",
        "x =[1,2,2]\n",
        "wx = 4\n",
        "wrec = 2\n",
        "wh = 3\n",
        "s0 = 0\n",
        "c = 2\n",
        "output = rnn_output(x,wx,wrec, wh,s0,c)\n",
        "print(f'OUTPUT: {output}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVQdkJ_X4JaY",
        "outputId": "e2816667-a3bc-4af0-8e63-4eb6539c43b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTPUT: 1248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10:\n",
        "\n",
        "Given the following input sequence with 3 vectors and 4 elements for each vector, and the self-attention mechanism parameters:\n",
        "\n",
        "Input Sequence:\n",
        "[\n",
        "[\n",
        "4\n",
        ",\n",
        "2\n",
        ",\n",
        "1\n",
        ",\n",
        "5\n",
        "]\n",
        ",\n",
        "[\n",
        "2\n",
        ",\n",
        "1\n",
        ",\n",
        "4\n",
        ",\n",
        "2\n",
        "]\n",
        ",\n",
        "[\n",
        "4\n",
        ",\n",
        "7\n",
        ",\n",
        "0\n",
        ",\n",
        "2\n",
        "]\n",
        "]\n",
        "[[4,2,1,5],[2,1,4,2],[4,7,0,2]]\n",
        "\n",
        "Parameters:\n",
        "### Weight Matrices (for demonstration purposes)\n",
        "\\[ Query Weight = \\begin{bmatrix}\n",
        "0.5 & 0 & 0 & 0 \\\\\n",
        "0 & 0.3 & 0 & 0 \\\\\n",
        "0 & 0 & 0.2 & 0 \\\\\n",
        "0 & 0 & 0 & 0.1\n",
        "\\end{bmatrix} \\]\n",
        "\\[ Key Weight = \\begin{bmatrix}\n",
        "0.4 & 0 & 0 & 0 \\\\\n",
        "0 & 0.6 & 0 & 0 \\\\\n",
        "0 & 0 & 0.2 & 0 \\\\\n",
        "0 & 0 & 0 & 0.8\n",
        "\\end{bmatrix} \\]\n",
        "\\[ Value Weight = \\begin{bmatrix}\n",
        "0.1 & 0 & 0 & 0 \\\\\n",
        "0 & 0.9 & 0 & 0 \\\\\n",
        "0 & 0 & 0.6 & 0 \\\\\n",
        "0 & 0 & 0 & 0.3\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "(Hint: Attention\n",
        "\n",
        "(Q,K,V)= softmax\n",
        "(QKT/dk))V , where Q=XWQ, K=XWK , V=XWV , X is the input, Wi is the weight matrix, dk is the scale factor.)\n",
        "\n",
        "Calculate the Query vector, Key vector and Value vector given the above input and parameters.\n",
        "\n",
        "(i) Show your calculation process for the first vector [4,2,1,5].\n",
        "\n",
        "(ii) Show the result for the whole input sequence."
      ],
      "metadata": {
        "id": "pZLi-SI45U1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "\n",
        "### **Answer 10 (i)**\n",
        "<br/>\n",
        "\n",
        "**Showing the calculation for Question 10(i) through manual calculations and below cell will display the answer in code:**\n",
        "\n",
        "\n",
        "**First Vector Calculation [4, 2, 1, 5]:**\n",
        "\n",
        "\n",
        "Q_1 =\n",
        "\\begin{bmatrix}\n",
        "4 & 2 & 1 & 5\n",
        "\\end{bmatrix}\n",
        "\n",
        "\\[ Query Weight = \\begin{bmatrix}\n",
        "0.5 & 0 & 0 & 0 \\\\\n",
        "0 & 0.3 & 0 & 0 \\\\\n",
        "0 & 0 & 0.2 & 0 \\\\\n",
        "0 & 0 & 0 & 0.1\n",
        "\\end{bmatrix} \\]\n",
        "\\[ Key Weight = \\begin{bmatrix}\n",
        "0.4 & 0 & 0 & 0 \\\\\n",
        "0 & 0.6 & 0 & 0 \\\\\n",
        "0 & 0 & 0.2 & 0 \\\\\n",
        "0 & 0 & 0 & 0.8\n",
        "\\end{bmatrix} \\]\n",
        "\\[ Value Weight = \\begin{bmatrix}\n",
        "0.1 & 0 & 0 & 0 \\\\\n",
        "0 & 0.9 & 0 & 0 \\\\\n",
        "0 & 0 & 0.6 & 0 \\\\\n",
        "0 & 0 & 0 & 0.3\n",
        "\\end{bmatrix} \\]\n",
        "\n",
        "\n",
        "Calculate each element of\n",
        "Q1 =\n",
        "\n",
        "*   Q1[0] = 4 * 0.5 + 2 * 0 + 1 * 0 + 5 * 0 = 2\n",
        "*   Q1[1] = 4 * 0 + 2 * 0.3 + 1 * 0 + 5 * 0 = 0.6\n",
        "\n",
        "*   Q1[2] = 4 * 0 + 2 * 0 + 1 * 0.2 + 5 * 0 = 0.2\n",
        "*   Q1[3] = 4 * 0 + 2 * 0 + 1 * 0 + 5 * 0.1 = 0.5\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "Calculate each element of\n",
        "K1 =\n",
        "\n",
        "*   K1[0] = 4 * 0.4 + 2 * 0 + 1 * 0 + 5 * 0 = 1.6\n",
        "*   K1[1] = 4 * 0 + 2 * 0.6 + 1 * 0 + 5 * 0 = 1.2\n",
        "\n",
        "*   K1[2] = 4 * 0 + 2 * 0 + 1 * 0.2 + 5 * 0 = 0.2\n",
        "*   K1[3] = 4 * 0 + 2 * 0 + 1 * 0 + 5 * 0.8 = 4\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "Calculate each element of\n",
        "V1 =\n",
        "\n",
        "*   V1[0] = 4 * 0.1 + 2 * 0 + 1 * 0 + 5 * 0 = 0.4\n",
        "*   V1[1] = 4 * 0 + 2 * 0.9 + 1 * 0 + 5 * 0 = 1.8\n",
        "\n",
        "*   V1[2] = 4 * 0 + 2 * 0 + 1 * 0.6 + 5 * 0 = 0.6\n",
        "*   V1[3] = 4 * 0 + 2 * 0 + 1 * 0 + 5 * 0.3 = 0.15\n",
        "<br/>\n",
        "\n",
        "**So, Q1 = [ 2, 0.6, 0.2, 5]**\n",
        "<br/>\n",
        "\n",
        "**So, K1 = [ 1.6, 1.2, 0.2, 4]**\n",
        "<br/>\n",
        "\n",
        "**So, V1 = [ 0.4, 1.8, 0.6, 0.15]**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "***The above calculation is shown here to show the calculation process for the first vector and the below code is to show the result for the whole input sequence for Question 10***"
      ],
      "metadata": {
        "id": "fc5fzsKkH_P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answering 10(i) and 10(ii) through the python code:\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "# Input sequence\n",
        "X = np.array([\n",
        "    [4, 2, 1, 5],\n",
        "    [2, 1, 4, 2],\n",
        "    [4, 7, 0, 2]\n",
        "])\n",
        "\n",
        "# Weight matrices\n",
        "W_Q = np.array([\n",
        "    [0.5, 0, 0, 0],\n",
        "    [0, 0.3, 0, 0],\n",
        "    [0, 0, 0.2, 0],\n",
        "    [0, 0, 0, 0.1]\n",
        "])\n",
        "\n",
        "W_K = np.array([\n",
        "    [0.4, 0, 0, 0],\n",
        "    [0, 0.6, 0, 0],\n",
        "    [0, 0, 0.2, 0],\n",
        "    [0, 0, 0, 0.8]\n",
        "])\n",
        "\n",
        "W_V = np.array([\n",
        "    [0.1, 0, 0, 0],\n",
        "    [0, 0.9, 0, 0],\n",
        "    [0, 0, 0.6, 0],\n",
        "    [0, 0, 0, 0.3]\n",
        "])\n",
        "\n",
        "Q = np.dot(X, W_Q)\n",
        "K = np.dot(X, W_K)\n",
        "V = np.dot(X, W_V)\n",
        "\n",
        "print(f\"First Query Vector: {Q[0]}\")\n",
        "print(f\"First Key Vector: {K[0]}\")\n",
        "print(f\"First Value Vector: {V[0]}\")\n",
        "\n",
        "print(\"Query Vector:\")\n",
        "print(Q)\n",
        "\n",
        "print(\"Key Vector:\")\n",
        "print(K)\n",
        "\n",
        "print(\"Value Vector:\")\n",
        "print(V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XjLpbFIpAzZ",
        "outputId": "fb7e9426-5987-43b6-9e8d-bcfb07987aa8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Query Vector: [2.  0.6 0.2 0.5]\n",
            "First Key Vector: [1.6 1.2 0.2 4. ]\n",
            "First Value Vector: [0.4 1.8 0.6 1.5]\n",
            "Query Vector:\n",
            "[[2.  0.6 0.2 0.5]\n",
            " [1.  0.3 0.8 0.2]\n",
            " [2.  2.1 0.  0.2]]\n",
            "Key Vector:\n",
            "[[1.6 1.2 0.2 4. ]\n",
            " [0.8 0.6 0.8 1.6]\n",
            " [1.6 4.2 0.  1.6]]\n",
            "Value Vector:\n",
            "[[0.4 1.8 0.6 1.5]\n",
            " [0.2 0.9 2.4 0.6]\n",
            " [0.4 6.3 0.  0.6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 11:\n",
        "Based on your calculations above\n",
        "\n",
        "(i) Calculate the raw attention scores (you donâ€™t need to apply the scale factor or the softmax function.)for the second vector of the input. Show your calculation process and result.\n",
        "\n",
        "(ii) Then you apply the softmax function to this raw attention scores to get the attention score (you donâ€™t need to apply the scale factor). Your result can contain the exponential term.\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n"
      ],
      "metadata": {
        "id": "JYxASUlcNNzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answering the question 11 (i):**\n",
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "aoN8gFjLQ1eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Showing my calculation process and result through manual for Question 11(i) and below cell will display the answer in code:**\n",
        "\n",
        "Detailed Dot Product Calculation:\n",
        "\n",
        "\n",
        "RawÂ AttentionÂ Scores=Q2â‹…K Transpose\n",
        "\n",
        "For the second input vector:\n",
        "\n",
        "Q2 = [1, 0.3, 0.8, 0.2]\n",
        "<br/>\n",
        "\n",
        "Key matrix:\n",
        "\n",
        "\\[ K =\\begin{bmatrix}\n",
        "1.6 & 1.2 & 0.2 & 4.0 \\\\\n",
        "0.8 & 0.6 & 0.8 & 1.6 \\\\\n",
        "1.6 & 4.2 & 0 & 1.6 \\\\\n",
        "\\end{bmatrix}\n",
        "\n",
        "]  \n",
        "\n",
        "\n",
        "Transposed Key matrix:\n",
        "\n",
        "\\[K Transpose =\n",
        "\\begin{bmatrix}\n",
        "1.6 & 0.8 & 1.6 \\\\\n",
        "1.2 & 0.6 & 4.2 \\\\\n",
        "0.2 & 0.8 & 0 \\\\\n",
        "4.0 & 1.6 & 1.6\n",
        "\\end{bmatrix}\n",
        "\n",
        "]  \n",
        "\n",
        "**Computing the dot products:**\n",
        "<br/>\n",
        "\n",
        "\n",
        "*   Raw Attention Scores [0] = (1 * 1.6) + (0.3 * 1.2) + (0.8 * .2) +(0.2 * 4.0) = 2.92\n",
        "*   Raw Attention Scores [1] = (1 * 0.8) + (0.3 * 0.6) + (0.8 * 0.8) +(0.2 * 1.6) = 1.94\n",
        "\n",
        "*   Raw Attention Scores [2] = (1 * 1.6) + (0.3 * 4.2) + (0.8 * 0) +(0.2 * 1.6) = 3.18\n",
        "\n",
        "**Raw Attention Scores: [ 2.92, 1.94, 3.18]**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vNhnMLYn--UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answering the question 11(i) through coding:\n",
        "\n",
        "# To calcualate the raw attention score for the second vector without the applying the scale factor (dk)\n",
        "\n",
        "# The score is calculated by taking the dot product of the Query Vector (Q2) with Key Vector (K) of the respective word we're scoring.\n",
        "# So, if we're processing the self-attenction for the word in position #1.\n",
        "# The first score would be the dot product of Q2 and K1 and second score would be the dot product of Q2 and K2 and so on.\n",
        "# Mathematically it requires the mulitiplying the query vector with the transponse of Key Matrix\n",
        "\n",
        "# Therefore Attention scores = Q2. K.Transpose\n",
        "\n",
        "\n",
        "\n",
        "raw_attention_scores = np.dot(Q[1], K.T)\n",
        "# Q[1] is the second query vector\n",
        "# K.T is the transpose of the Key Matrix\n",
        "\n",
        "print(\"Raw Attention Scores and this is answering the question 11(i):\")\n",
        "print(raw_attention_scores)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVzSiFszGyGv",
        "outputId": "9896f5e2-2cce-4f7a-c625-81fd0e3d92ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Attention Scores and this is answering the question 11(i):\n",
            "[2.92 1.94 3.18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answering the question 11 (ii):**\n",
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "zfxcbR7WRBb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Showing my calculation process and result through manual for Question 11(ii) and below cell will display the answer in code:**\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{Softmax}(2.92) &= \\frac{e^{2.92}}{e^{2.92} + e^{1.94} + e^{3.18}} = 18.541 / 49.545 = 0.3742 \\\\\n",
        "\\text{Softmax}(1.94) &= \\frac{e^{1.94}}{e^{2.92} + e^{1.94} + e^{3.18}} = 6.958 / 49.545 = 0.1404 \\\\\n",
        "\\text{Softmax}(3.18) &= \\frac{e^{3.18}}{e^{2.92} + e^{1.94} + e^{3.18}} = 24.046 / 49.545 = 0.4853\n",
        "\\end{align*}\n",
        "\n",
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "RvUEcRNVKxDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answering the question 11(ii) through PyTorch:\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Apply softmax and using the softmax from pytorch.\n",
        "# Not applying the\n",
        "\n",
        "Softmax = F.softmax(torch.tensor(raw_attention_scores), dim=-1)\n",
        "\n",
        "print(\"Attention Scores and this is answering the question 11(ii):\")\n",
        "print(Softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpzZKbZJQJf_",
        "outputId": "735ea732-a619-4c96-c81b-5454ca7f0009"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Scores and this is answering the question 11(ii):\n",
            "tensor([0.3742, 0.1404, 0.4853], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 12:\n",
        "\n",
        "Calculate the final representation of the second vector after this self-attention mechanism, using the\n",
        "ğ‘„\n",
        "Q vector,\n",
        "ğ¾\n",
        "K vector,\n",
        "ğ‘‰\n",
        "V vector and the attention value you calculated above. For the attention score, you can just use the raw attention scores. Show your calculation process and the result."
      ],
      "metadata": {
        "id": "f5cV2rT0Swwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### Answer 12:\n",
        "\n",
        "**Showing my calculation process and result through manual for Question 12 and below cell will display the answer in code:**\n",
        "\n",
        "\\[\n",
        "V = \\begin{bmatrix}\n",
        "0.4 & 1.8 & 0.6 & 1.5 \\\\\n",
        "0.2 & 0.9 & 2.4 & 0.6 \\\\\n",
        "0.4 & 6.3 & 0 & 0.6\n",
        "\\end{bmatrix}\n",
        "\\]\n",
        "\n",
        "Softmax values = \\\\begin{bmatrix}\n",
        "0.3742 & 0.1404 & 0.4853\n",
        "\\end{bmatrix}\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "**Calculate each component:**\n",
        "\n",
        "\n",
        "*   0.3742 * 0.4 = 0.1432\n",
        "*   0.1404 * 0.2 = 0.0280\n",
        "\n",
        "*   0.4853 * 0.4 = 0.1941\n",
        "\n",
        "*   0.3742 * 1.8 = 0.6735\n",
        "*   0.1404 * 0.9 = 0.1263\n",
        "\n",
        "*   0.4853 * 6.3 = 3.0573\n",
        "*   0.3742 * 0.6 = 0.2245\n",
        "*   0.1404 * 2.4 = 0.3369\n",
        "\n",
        "*   0.4853 * 0 = 0\n",
        "*   0.3742 * 1.5 = 0.5613\n",
        "*   0.1404 * 0.6 = 0.0842\n",
        "\n",
        "*   0.4853 * 0.6 = 0.2911\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "**Summing these values for each component gives the final representation:**\n",
        "\n",
        "\\begin{bmatrix}\n",
        "0.1432 + 0.0280 + 0.1941 & 0.6735 + 0.1263 + 3.0573 & 0.2245 + 0.3369 + 0 & 0.5613 + 0.0842 + 0.2911\n",
        "\\end{bmatrix}\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Final Representation of the Second Vector:**\n",
        "\n",
        "\\\\begin{bmatrix}\n",
        "0.3653 & 3.8571 & 0.5614 & 0.9366\n",
        "\\end{bmatrix}\n",
        "\n"
      ],
      "metadata": {
        "id": "EJVjMBUoTHqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answering the question 12 through coding:\n",
        "\n",
        "output = np.dot(Softmax, V)\n",
        "\n",
        "print(\"\\nFinal Representation of the second vector:\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHs5Fo2DSKc2",
        "outputId": "853ad521-02b5-47db-933c-436e2a920a60"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Representation of the second vector:\n",
            "[0.37191039 3.85760073 0.56160598 0.93679595]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ripjR2-rsxn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}