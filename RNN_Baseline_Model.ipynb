{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNifP8TmsyqvIGKXteSIV0P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatanadikatla/pytorch/blob/main/RNN_Baseline_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchtext\n",
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lm5pwj14-u2",
        "outputId": "2efd247c-dafe-4225-f9fb-fb872a9163fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchtext 0.18.0\n",
            "Uninstalling torchtext-0.18.0:\n",
            "  Successfully uninstalled torchtext-0.18.0\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Summary:**\n",
        "The project focussses on building a baseline sentiment analysis model using a Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) units. The model is taken from Standford and trained on Stanford Sentiment Treebank (SST) dataset, which contains sentences labeled with sentiment categories. The goal for this model to classify the sentiment of sentences as positive or negative or neutral.\n",
        "\n",
        "**Hyperparameters:**\n",
        "The provided hyperparameters are provided already by the course team. embedding_dim = 128, hidden_dim =128, batchsize =32 and chose adam optimizer of 0.01 (learning rate). As mentioned above this is considered a baseline model.\n",
        "\n",
        "**Defining the RNN model:**\n",
        "Firstly embedding that coverts words into dense vectors, lstm - this layer proccesses the embedded text sequences, fully connected layer - this to outputs the final predictions.\n",
        "Initiating a zerostate fuction to initialize the hidden state with zeros.\n",
        "Initiating the forward function to forward pass of the model.\n",
        "\n",
        "**Training the model:**\n",
        "This training function iterates over the training data, performs forward and backward passes, updates the model parameters, and computes the training loss and accuracy.\n",
        "\n",
        "**Evaluate and Test model:**\n",
        "The evaluation function computes the loss and accuracy on the validation data without updating the model parameters(no back propagation).\n",
        "The test function evaluates the model on the test data to report the final performance. Based on this baseline model performance : **Test Accuracy is 56.6%**\n",
        "\n",
        "**Summary:**\n",
        "This project demonstrates how to build a sentiment analysis model using pytorch and torchtext (Version 0.60) with an LSTM-based RNN. The model is trained and evaluated on SST dataset, with keysteps data preprocessing, couple data analysis to quickly analyze the train data examples, model definition, training, evaluation, and testing. This model implemented using as a baseline to next furthermore accuracy improvement on the sentimenet analysis task in downstream."
      ],
      "metadata": {
        "id": "ab2pnyKOZTga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-ZvzcAcloVA7",
        "outputId": "920b8f4d-25dc-4463-a673-522e8188139c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading trainDevTestTrees_PTB.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "trainDevTestTrees_PTB.zip: 100%|██████████| 790k/790k [00:02<00:00, 278kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting\n"
          ]
        }
      ],
      "source": [
        "import copy # this module provides functions to duplicate objects. It seems to be imported but not yet used in the code\n",
        "import torch # The MAIN PyTorch package\n",
        "from torch import nn # contains the essential modules for building NN in pytorch.\n",
        "from torch import optim # Provides optimization algorithms, such as SGD, Adam, etc\n",
        "import torchtext # A library for text processing that works well with pytorch (Currently a version 0.6.0 is being used in this code)\n",
        "from torchtext import data # A module in torchtext used for data handling\n",
        "from torchtext import datasets # provides datasets, including various NLP datasets.\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True) # Sequential = True indicates that the data consists of sequences.\n",
        "#Batch_first=True Ensure that batch dimenstion is the first dimension in the tensor. # lower=True Converts all the text to lowercase\n",
        "\n",
        "LABEL = data.LabelField() # A subclass of Field specifically for handling labels in a classification task.\n",
        "\n",
        "# load data splits\n",
        "train_data, val_data, test_data = datasets.SST.splits(TEXT, LABEL) #datasets.SST.splits - Loads the Standford Sentiment Treebank(SST) dataset and splits the dataset\n",
        "\n",
        "# build dictionary\n",
        "# build_vocab: Creates a mapping from tokens(words) to indices. This is essential for converting text data into numerical form that can be used by NN.\n",
        "TEXT.build_vocab(train_data) # Builds the vocabulary for the text field using the training data.\n",
        "LABEL.build_vocab(train_data)# Builds the vocabulary for the label field using the training data.\n",
        "\n",
        "# hyperparameters\n",
        "vocab_size = len(TEXT.vocab) # the size of the vocabulary (number of unique tokens in the training data)\n",
        "label_size = len(LABEL.vocab) # the number of unique labels (classes) in the traning data\n",
        "padding_idx = TEXT.vocab.stoi['<pad>'] # The index used for padding sequences to the same length\n",
        "embedding_dim = 128 # The size of the word embeddings (dense vector representation of words)\n",
        "hidden_dim = 128 # Size of the hidden layers in the model\n",
        "\n",
        "# build iterators\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    batch_size=32)\n",
        "\n",
        "# Data.bucketiterator.splits - Creates iterators for the training, validation and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars (train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6dMitAM48Bp",
        "outputId": "6e345674-97ce-4d62-99f1-dd03008966f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '``', 'conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.'], 'label': 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(val_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeUcV2gI7NrN",
        "outputId": "d5b9b5f4-071d-460b-a2d3-09b6978c882d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.'], 'label': 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(test_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll5LVsPuIZAd",
        "outputId": "dc55c418-0f5b-421f-9665-a9500276f4e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['effective', 'but', 'too-tepid', 'biopic'], 'label': 'neutral'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Num Train: {len(train_data)}')\n",
        "print(f'Num Val: {len(val_data)}')\n",
        "print(f'Num Test: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXMilSYkrWor",
        "outputId": "1028cc54-8b97-44a9-f2f1-7be5e6a11c31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Train: 8544\n",
            "Num Val: 1101\n",
            "Num Test: 2210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocabulary size: {len(TEXT.vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX6FmQwgnHGd",
        "outputId": "7112366d-bda4-4702-e0f8-0dc622bd6a78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 16581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocabulary size: {len(LABEL.vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl3ay5DSoDHL",
        "outputId": "afc28f7d-a769-44cc-f7c6-be4fa85fa550"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.freqs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoUvVdkuoYuU",
        "outputId": "a007c4d8-42be-44e6-da50-3c04c044cb6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'positive': 3610, 'negative': 3310, 'neutral': 1624})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1oOvGFjolBc",
        "outputId": "f846ac5a-9d1b-4795-f992-075ceb446e87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('.', 8024), ('the', 7303), (',', 7131), ('a', 5281), ('and', 4473), ('of', 4396), ('to', 3021), ('is', 2561), (\"'s\", 2544), ('it', 2422), ('that', 1954), ('in', 1888), ('as', 1296), ('but', 1172), ('film', 1162), ('with', 1139), ('for', 1023), ('this', 998), ('movie', 976), ('an', 972)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.itos[:10])\n",
        "#Tokens corresponding to the first 10 indices (0,1....9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EESjeh3Ao3ai",
        "outputId": "52576152-155d-4509-f3b5-f00f195d1021"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', '.', 'the', ',', 'a', 'and', 'of', 'to', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN (torch.nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, padding_idx):\n",
        "    super().__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.label_size = label_size\n",
        "    self.num_layers = 1\n",
        "    self.embedding = torch.nn.Embedding(vocab_size, embedding_dim, padding_idx = padding_idx)\n",
        "    # self.rnn = torch.nn.RNN(embedding_dim,hidden_dim, nonlinearity='relu',batch_first=True)\n",
        "    self.lstm = torch.nn.LSTM(embedding_dim,hidden_dim, batch_first=True)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def zero_state(self, batch_size):\n",
        "    # Implement the function, which returns an initial hidden state.\n",
        "    return torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
        "\n",
        "\n",
        "  def forward(self, text):\n",
        "    #text dim = [sentence length, batchsize]\n",
        "    embedded = self.embedding(text)\n",
        "    #embedded dim = [sentence length, batchsize, embedding_dim]\n",
        "    batch_size = text.size(0)\n",
        "    h_0 = self.zero_state(batch_size).to(text.device)  # Ensure the hidden state is on the same device as the input\n",
        "    output, (hidden,cell) = self.lstm(embedded)\n",
        "    #output dim = [sentence length, batchsize, hidden_dim]\n",
        "    #hidden dim = [1, batch_size, hidden_dim]\n",
        "    hidden = hidden.squeeze_(0)\n",
        "    #hidden_dim = [batch_size, hidden_dim]\n",
        "\n",
        "    return self.fc(hidden)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xl4a22ZVAmBk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,train_iter, optimizer, criterion, num_epochs =10):\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in train_iter:\n",
        "      optimizer.zero_grad()\n",
        "      text, labels = batch.text, batch.label\n",
        "      output = model(text)\n",
        "      loss = criterion(output, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += (output.argmax(1) ==labels).sum().item()\n",
        "\n",
        "      _, predicted = torch.max(output.data,1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = epoch_loss/len(train_iter)\n",
        "    avg_acc = epoch_acc/len(train_iter.dataset)\n",
        "\n",
        "    epoch_accuracy = 100*correct/total\n",
        "\n",
        "\n",
        "    print(f' Epoch {epoch+1}, Train Loss: {avg_loss}, Train Accuracy: {epoch_accuracy}%')\n",
        "\n"
      ],
      "metadata": {
        "id": "SdxptgPyTou5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, val_iter, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for batch in val_iter:\n",
        "    text, labels = batch.text, batch.label\n",
        "    output = model(text)\n",
        "    loss = criterion(output, labels)\n",
        "    epoch_loss +=loss.item()\n",
        "    epoch_acc += (output.argmax(1)==labels).sum().item()\n",
        "    _, predicted = torch.max(output.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  avg_loss = epoch_loss/len(val_iter)\n",
        "  avg_acc = epoch_acc/len(val_iter.dataset)\n",
        "\n",
        "  epoch_accuracy = 100*correct/total\n",
        "\n",
        "  print(f'Validation Loss: {avg_loss},  Validation Accuracy: {epoch_accuracy}%')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yXkwIwK6-dWw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_iter, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for batch in test_iter:\n",
        "    text, labels = batch.text, batch.label\n",
        "    output = model(text)\n",
        "    loss = criterion(output, labels)\n",
        "    epoch_loss +=loss.item()\n",
        "    epoch_acc += (output.argmax(1)==labels).sum().item()\n",
        "    _, predicted = torch.max(output.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  avg_loss = epoch_loss/len(test_iter)\n",
        "  avg_acc = epoch_acc/len(test_iter.dataset)\n",
        "\n",
        "  epoch_accuracy = 100*correct/total\n",
        "\n",
        "  print(f'Test Loss: {avg_loss},  Test Accuracy: {epoch_accuracy}%')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fu9TNlNZADxX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = RNN(vocab_size,embedding_dim,hidden_dim,label_size, padding_idx)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "nVbzwTATH143"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model,train_iter, optimizer, criterion, num_epochs =10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNizhEh9IIgz",
        "outputId": "5d3a0030-b901-4e42-bb04-2abe4511436a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch 1, Train Loss: 1.0501589143320862, Train Accuracy: 41.95926966292135%\n",
            " Epoch 2, Train Loss: 1.0452366681134657, Train Accuracy: 42.08801498127341%\n",
            " Epoch 3, Train Loss: 1.0369028123130513, Train Accuracy: 43.36376404494382%\n",
            " Epoch 4, Train Loss: 0.9949213277534599, Train Accuracy: 52.949438202247194%\n",
            " Epoch 5, Train Loss: 0.8846838114859906, Train Accuracy: 61.879681647940075%\n",
            " Epoch 6, Train Loss: 0.7342621353681614, Train Accuracy: 70.44709737827715%\n",
            " Epoch 7, Train Loss: 0.6047985041409396, Train Accuracy: 75.50327715355806%\n",
            " Epoch 8, Train Loss: 0.4994143441821752, Train Accuracy: 80.31367041198502%\n",
            " Epoch 9, Train Loss: 0.3979665526234255, Train Accuracy: 85.27621722846442%\n",
            " Epoch 10, Train Loss: 0.3114879262469681, Train Accuracy: 89.17368913857678%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on validation data\n",
        "eval_model(model, val_iter, criterion)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ecVD1L9IQim",
        "outputId": "d216806d-e8f5-4a4e-dbe1-8e461670f4a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.349814053944179,  Validation Accuracy: 56.130790190735695%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_model(model, test_iter, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4guvxBNjtUEn",
        "outputId": "703eea5c-7241-4ed1-d6e6-ab3fc3edd179"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.3148631725992475,  Test Accuracy: 56.60633484162896%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MgZeHJaxAy_M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}