{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOkgDfq+V8LZMXrHvdCx59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatanadikatla/pytorch/blob/main/RNN_Building_Training_and_Evaluation_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchtext\n",
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "2Lm5pwj14-u2",
        "outputId": "4694fd65-64d9-4ac5-904f-c71f897e386c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchtext 0.6.0\n",
            "Uninstalling torchtext-0.6.0:\n",
            "  Successfully uninstalled torchtext-0.6.0\n",
            "Collecting torchtext==0.6.0\n",
            "  Using cached torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.6.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              },
              "id": "327095ebf4bb465eb0f01af2f730b584"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-ZvzcAcloVA7"
      },
      "outputs": [],
      "source": [
        "import copy # this module provides functions to duplicate objects. It seems to be imported but not yet used in the code\n",
        "import torch # The MAIN PyTorch package\n",
        "from torch import nn # contains the essential modules for building NN in pytorch.\n",
        "from torch import optim # Provides optimization algorithms, such as SGD, Adam, etc\n",
        "import torchtext # A library for text processing that works well with pytorch (Currently a version 0.6.0 is being used in this code)\n",
        "from torchtext import data # A module in torchtext used for data handling\n",
        "from torchtext import datasets # provides datasets, including various NLP datasets.\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True) # Sequential = True indicates that the data consists of sequences.\n",
        "#Batch_first=True Ensure that batch dimenstion is the first dimension in the tensor. # lower=True Converts all the text to lowercase\n",
        "\n",
        "LABEL = data.LabelField() # A subclass of Field specifically for handling labels in a classification task.\n",
        "\n",
        "# load data splits\n",
        "train_data, val_data, test_data = datasets.SST.splits(TEXT, LABEL) #datasets.SST.splits - Loads the Standford Sentiment Treebank(SST) dataset and splits the dataset\n",
        "\n",
        "# build dictionary\n",
        "# build_vocab: Creates a mapping from tokens(words) to indices. This is essential for converting text data into numerical form that can be used by NN.\n",
        "TEXT.build_vocab(train_data) # Builds the vocabulary for the text field using the training data.\n",
        "LABEL.build_vocab(train_data)# Builds the vocabulary for the label field using the training data.\n",
        "\n",
        "# hyperparameters\n",
        "vocab_size = len(TEXT.vocab) # the size of the vocabulary (number of unique tokens in the training data)\n",
        "label_size = len(LABEL.vocab) # the number of unique labels (classes) in the traning data\n",
        "padding_idx = TEXT.vocab.stoi['<pad>'] # The index used for padding sequences to the same length\n",
        "embedding_dim = 128 # The size of the word embeddings (dense vector representation of words)\n",
        "hidden_dim = 128 # Size of the hidden layers in the model\n",
        "\n",
        "# build iterators\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    batch_size=32)\n",
        "\n",
        "# Data.bucketiterator.splits - Creates iterators for the training, validation and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars (train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6dMitAM48Bp",
        "outputId": "1cfcd7f3-8a58-40c6-8815-ce639013525d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '``', 'conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.'], 'label': 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(val_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeUcV2gI7NrN",
        "outputId": "085ee824-c43c-40f5-cade-a2b775b2dca6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.'], 'label': 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(test_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll5LVsPuIZAd",
        "outputId": "30e08279-ed00-44e9-85b5-37dd49912cb1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['effective', 'but', 'too-tepid', 'biopic'], 'label': 'neutral'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Num Train: {len(train_data)}')\n",
        "print(f'Num Val: {len(val_data)}')\n",
        "print(f'Num Test: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXMilSYkrWor",
        "outputId": "e3e8215b-134c-4b5e-b210-d1edd8b5a6f2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Train: 8544\n",
            "Num Val: 1101\n",
            "Num Test: 2210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocabulary size: {len(TEXT.vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX6FmQwgnHGd",
        "outputId": "53cbac3e-6bcb-44b4-8b94-f7645cb26764"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 16581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocabulary size: {len(LABEL.vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl3ay5DSoDHL",
        "outputId": "3b954748-714e-47cb-fb32-38f01cf317b6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.freqs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoUvVdkuoYuU",
        "outputId": "35c1942c-9662-402f-81b3-8fdfd5fe4738"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'positive': 3610, 'negative': 3310, 'neutral': 1624})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1oOvGFjolBc",
        "outputId": "1cb814d5-d7bf-49ad-a0c2-ac2ef4a617f7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('.', 8024), ('the', 7303), (',', 7131), ('a', 5281), ('and', 4473), ('of', 4396), ('to', 3021), ('is', 2561), (\"'s\", 2544), ('it', 2422), ('that', 1954), ('in', 1888), ('as', 1296), ('but', 1172), ('film', 1162), ('with', 1139), ('for', 1023), ('this', 998), ('movie', 976), ('an', 972)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.itos[:10])\n",
        "#Tokens corresponding to the first 10 indices (0,1....9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EESjeh3Ao3ai",
        "outputId": "3cf747da-59f8-4df9-909c-814cfbfa06b1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', '.', 'the', ',', 'a', 'and', 'of', 'to', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN (torch.nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, padding_idx):\n",
        "    super().__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.label_size = label_size\n",
        "    self.num_layers = 1\n",
        "    self.embedding = torch.nn.Embedding(input_dim, embedding_dim, padding_idx = padding_idx)\n",
        "    # self.rnn = torch.nn.RNN(embedding_dim,hidden_dim, nonlinearity='relu',batch_first=True)\n",
        "    self.lstm = torch.nn.LSTM(embedding_dim,hidden_dim, batch_first=True)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def zero_state(self, batch_size):\n",
        "    # Implement the function, which returns an initial hidden state.\n",
        "    return torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
        "\n",
        "\n",
        "  def forward(self, text):\n",
        "    #text dim = [sentence length, batchsize]\n",
        "    embedded = self.embedding(text)\n",
        "    #embedded dim = [sentence length, batchsize, embedding_dim]\n",
        "    batch_size = text.size(0)\n",
        "    h_0 = self.zero_state(batch_size).to(text.device)  # Ensure the hidden state is on the same device as the input\n",
        "    output, (hidden, cell) = self.lstm(embedded)\n",
        "    #output dim = [sentence length, batchsize, hidden_dim]\n",
        "    #hidden dim = [1, batch_size, hidden_dim]\n",
        "    hidden = hidden.squeeze_(0)\n",
        "    #hidden_dim = [batch_size, hidden_dim]\n",
        "\n",
        "    return self.fc(hidden)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xl4a22ZVAmBk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,train_iter, optimizer, criterion, num_epochs =10):\n",
        "  train_losses = []\n",
        "  train_accuracies = []\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in train_iter:\n",
        "      optimizer.zero_grad()\n",
        "      text, labels = batch.text, batch.label\n",
        "      output = model(text)\n",
        "      loss = criterion(output, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += (output.argmax(1) ==labels).sum().item()\n",
        "\n",
        "      _, predicted = torch.max(output.data,1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = epoch_loss/len(train_iter)\n",
        "    avg_acc = epoch_acc/len(train_iter.dataset)\n",
        "\n",
        "    epoch_accuracy = 100*correct/total\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    # print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.4f}, Epoch Accuracy: {epoch_accuracy:.2f}%, Train_loss: {train_losses}, Train_accuracy: {train_accuracies}')\n",
        "    print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.4f}, Epoch Accuracy: {epoch_accuracy:.2f}%')\n",
        "    # print(f'Train Losses: {train_losses}, Train Accuracies: {train_accuracies}')\n",
        "\n"
      ],
      "metadata": {
        "id": "SdxptgPyTou5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, val_iter, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  val_losses = []\n",
        "  val_accuracies = []\n",
        "\n",
        "  for batch in val_iter:\n",
        "    text, labels = batch.text, batch.label\n",
        "    output = model(text)\n",
        "    loss = criterion(output, labels)\n",
        "    epoch_loss +=loss.item()\n",
        "    epoch_acc += (output.argmax(1)==labels).sum().item()\n",
        "    _, predicted = torch.max(output.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  avg_loss = epoch_loss/len(val_iter)\n",
        "  avg_acc = epoch_acc/len(val_iter.dataset)\n",
        "\n",
        "  epoch_accuracy = 100*correct/total\n",
        "\n",
        "  val_losses.append(avg_loss)\n",
        "  val_accuracies.append(epoch_accuracy)\n",
        "\n",
        "  print(f'Validation Loss: {val_losses},  Validation Accuracy: {val_accuracies}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yXkwIwK6-dWw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = RNN(vocab_size,embedding_dim,hidden_dim,label_size, padding_idx)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "nVbzwTATH143"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model,train_iter, optimizer, criterion, num_epochs =10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNizhEh9IIgz",
        "outputId": "2b6fb259-14f5-4654-f953-5ba83ac04018"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0501, Accuracy: 0.4187, Epoch Accuracy: 41.87%\n",
            "Epoch 2, Loss: 1.0445, Accuracy: 0.4208, Epoch Accuracy: 42.08%\n",
            "Epoch 3, Loss: 1.0375, Accuracy: 0.4313, Epoch Accuracy: 43.13%\n",
            "Epoch 4, Loss: 1.0140, Accuracy: 0.4752, Epoch Accuracy: 47.52%\n",
            "Epoch 5, Loss: 0.9840, Accuracy: 0.5051, Epoch Accuracy: 50.51%\n",
            "Epoch 6, Loss: 0.9304, Accuracy: 0.5640, Epoch Accuracy: 56.40%\n",
            "Epoch 7, Loss: 0.8355, Accuracy: 0.6369, Epoch Accuracy: 63.69%\n",
            "Epoch 8, Loss: 0.7428, Accuracy: 0.6917, Epoch Accuracy: 69.17%\n",
            "Epoch 9, Loss: 0.6774, Accuracy: 0.7283, Epoch Accuracy: 72.83%\n",
            "Epoch 10, Loss: 0.6411, Accuracy: 0.7539, Epoch Accuracy: 75.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on validation data\n",
        "eval_model(model, val_iter, criterion)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "eval_model (model, test_iter, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ecVD1L9IQim",
        "outputId": "d982245f-275f-4d6d-d1be-e107a12e35f9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: [1.0913020610809325],  Validation Accuracy: [40.05449591280654]\n",
            "Validation Loss: [1.0985716376985823],  Validation Accuracy: [40.90497737556561]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4guvxBNjtUEn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}